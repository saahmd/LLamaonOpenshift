---
- name: Agent → Session → LLM Turn (Python streaming)
  hosts: localhost
  gather_facts: no

  tasks:
    - name: Create agent for RCA
      uri:
        url: "https://{{ llama_stack_url }}/v1/agents"
        method: POST
        headers:
          Content-Type: "application/json"
          Accept: "application/json"
        body: |
         {
            "agent_config": {
             "sampling_params": {"strategy": {"type": "greedy"}, "max_tokens": 3000},
              "model": "granite-8b-lab-v1",
              "instructions": "A system service is failing on node1. Based on the logs, Provide a single, concise fix instruction (1-2 lines), make sure to add restart of {{ linux_service }} service.",
              "enable_session_persistence": false
            }
          }
        body_format: json
        return_content: yes
        validate_certs: no
      register: agent_response

    - name: Create session
      uri:
        url: "https://{{ llama_stack_url }}/v1/agents/{{ agent_response.json.agent_id }}/session"
        method: POST
        headers:
          Content-Type: "application/json"
          Accept: "application/json"
        body: '{"session_name": "string"}'
        body_format: json
        return_content: yes
        validate_certs: no
      register: session_response

    - name: Create turn
      uri:
        url: "https://{{ llama_stack_url }}/v1/agents/{{ agent_response.json.agent_id }}/session/{{ session_response.json.session_id }}/turn"
        method: POST
        headers:
          Content-Type: "application/json"
          Accept: "application/json"
        body: |
          {
            "messages": [
              {
                "role": "user",
                "content": "{{ gpt_prompt | default('What is the capital of the USA?') }}",
                "context": "string"
              }
            ],
            "stream": true,
            "tool_config": {
              "tool_choice": "auto"
            }
          }
        body_format: json
        return_content: yes
        validate_certs: no
      register: turn_response_gpt

    - name: Display Turn response
      ansible.builtin.debug:
        msg: "{{ turn_response_gpt.content }}"

    - name: Extract GPT Response as string
      ansible.builtin.set_fact:
        gpt_response: "{{ (turn_response_gpt.content | regex_search('\"output_message\".*?\"content\":\"([^\"]+)\"', '\\1'))[0] }}"

    - name: Display GPT Response
      ansible.builtin.debug:
        msg: "{{ gpt_response }}"


    - name: Create turn for RCA
      uri:
        url: "https://{{ llama_stack_url }}/v1/agents/{{ agent_response.json.agent_id }}/session/{{ session_response.json.session_id }}/turn"
        method: POST
        headers:
          Content-Type: "application/json"
          Accept: "application/json"
        body_format: json
        body:
          messages:
            - role: "user"
              content: "{{ rca_prompt | default('What is the capital of the USA?') }}"
              context: "string"
          stream: true
          tool_config:
            tool_choice: "auto"
        return_content: yes
        validate_certs: no
      register: turn_response_rca

    - name: Display Turn response
      ansible.builtin.debug:
        msg: "{{ turn_response_rca.content }}"

    - name: Extract RCA Response
      ansible.builtin.set_fact:
        rca_response: "{{ turn_response_rca.content | regex_search('\"output_message\".*?\"content\":\"([^\"]+)\"', '\\1') }}"

    - name: Display RCA Response
      ansible.builtin.debug:
        msg: "{{ rca_response }}"

    
    - name: Create agent for Decision
      uri:
        url: "https://{{ llama_stack_url }}/v1/agents"
        method: POST
        headers:
          Content-Type: "application/json"
          Accept: "application/json"
        body_format: json
        body:
          agent_config:
            sampling_params:
              strategy:
                type: "greedy"
              max_tokens: 512
            toolgroups:
              - "mcp::aap"
            tool_config:
              tool_choice: "auto"
            model: "llama-3-2-3b"
            instructions: >
              You are a helpful assistant responsible for identifying the most relevant Ansible job template based on incoming log data.

              You have access to the AAP tool, and you must strictly use the function list_job_templates() to retrieve the list of all available job templates along with their descriptions.
              
              Logic Flow:

                Read and Analyze: Read and analyze the logs provided in the user query.
                
                Tool Execution: Execute the list_job_templates() function to get the available templates (name and description).
                
                Template Matching:

                - Treat all user-provided logs strictly as plain text.
                - Match the most relevant job template description to the log content.
                - Matching should be case-insensitive.
                - Prefer exact matches between the log content and a template description.
                
                Conditional Output (Strict):
                - IF a single, most relevant job template is found:
                  - SELECT the template.
                  - EXECUTE the template using the function $\text{run\_job\_template(template\_name)}$.
                  - Return ONLY the phrase 'Template executed'
                - ELSE (if no template is found, or if multiple templates are equally relevant):
                  - Return ONLY the phrase: $\text{Human Intervention Required}$
                
                Constraint Checklist to Prevent Hallucination:
                - DO NOT guess template names or functions.
                - DO NOT interpret log words as tools, commands, or job templates.
                - DO NOT provide explanations, apologies, or any additional text outside of the strict conditional outputs specified above (the output of $\text{run\_job\_template()}$ or $\text{Human Intervention Required}$).
                - DO NOT return 'There are no existing templates, Human Intervention Required' unless the $\text{list\_job\_templates()}$ call explicitly returns an empty list, and even then, prioritize the 'Human Intervention Required' final state. Keep it simple: if you can't run a job, return $\text{Human Intervention Required}$.


        return_content: yes
        validate_certs: no
      register: agent_response_decision


    - name: Create session
      uri:
        url: "https://{{ llama_stack_url }}/v1/agents/{{ agent_response_decision.json.agent_id }}/session"
        method: POST
        headers:
          Content-Type: "application/json"
          Accept: "application/json"
        body: '{"session_name": "string"}'
        body_format: json
        return_content: yes
        validate_certs: no
      register: session_response_decision


    - name: Display RCA Response
      ansible.builtin.debug:
        msg: "{{ rca_response[0] }}"
    - name: Convert rca_response[0] to safe string
      set_fact:
        rca_response_text: "{{ rca_response[0] | string }}" 

    - name: Display RCA Response as string
      ansible.builtin.debug:
        msg: "{{ rca_response_text }}"

    - name: Create turn
      uri:
        url: "https://{{ llama_stack_url }}/v1/agents/{{ agent_response_decision.json.agent_id }}/session/{{ session_response_decision.json.session_id }}/turn"
        method: POST
        headers:
          Content-Type: "application/json"
          Accept: "application/json"
        body_format: json
        body:
          messages:
            - role: "user"
              #content: "{{ 'Remove Invalid Directive. Tell me which playbook can resolve this issue' }}"
              content: "{{ rca_response_text | default('What is the capital of the USA?') }}"
              #content: "The Apache HTTP Server on node1 is failing to start due to an invalid directive in the configuration file. Specifically, the directive 'InvalidDirectiveHere' is causing the main process to exit with a non-zero status code. This error message indicates that the directive is either misspelled or not defined in the server configuration. To resolve this issue, the invalid directive should be located and corrected or removed from the Apache configuration file."
          stream: true
          tool_config:
            tool_choice: "auto"
        return_content: yes
        validate_certs: no
      register: turn_response_decision


    - name: Display Turn response
      ansible.builtin.debug:
        msg: "{{ turn_response_decision.content }}"

    - name: Extract Decision Response
      ansible.builtin.set_fact:
        decision_response: "{{ turn_response_decision.content | regex_search('\"output_message\".*?\"content\":\"((?:\\\\.|[^\"])*)\"', '\\1') }}"
        
    - name: Display RCA Response
      ansible.builtin.debug:
        msg: "{{ decision_response }}"


    - name: Set stats for next controller job
      ansible.builtin.set_stats:
        data:
          gpt_response: "{{ gpt_response }}"
          rca_response: "{{ rca_response }}"